from ultralytics import YOLO
import cv2
import math 
import pyttsx3
import threading
import queue

# start webcam
cap = cv2.VideoCapture(0)
cap.set(3, 640)
cap.set(4, 480)

# Initialize the TTS engine
engine = pyttsx3.init()

# model
model = YOLO("yolo-Weights/yolov8n.pt")



# object classes
classNames = ["person", "bicycle", "car", "motorbike", "aeroplane", "bus", "train", "truck", "boat",
              "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
              "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella",
              "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat",
              "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup",
              "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli",
              "carrot", "hot dog", "pizza", "donut", "cake", "chair", "sofa", "pottedplant", "bed",
              "diningtable", "toilet", "tvmonitor", "laptop", "mouse", "remote", "keyboard", "cell phone",
              "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors",
              "teddy bear", "hair drier", "toothbrush", "Automobile", "Obstacle", "Person", "Road", "Sidewalk"
              ]

# Define a function to handle TTS
def speak_async(text):

    def run_tts():
        engine = pyttsx3.init()  # Create a new instance of the TTS engine
        engine.setProperty('rate', 150)
        engine.setProperty('volume', 1.0)
        engine.say(text)
        engine.runAndWait()

    # Run TTS in a background thread
    tts_thread = threading.Thread(target=run_tts)
    tts_thread.start()


while True:
    
    success, img = cap.read()
    results = model(img, stream=True, verbose=False)
    #left zone
    cv2.rectangle(img, (0,250), (320,480) , (255, 0 , 0),3, 1)
    #right zone
    cv2.rectangle(img, (320, 250), (640,480), (255, 0 , 0),3, 1)
    



    # coordinates
    for r in results:
        boxes = r.boxes

        for box in boxes:
            # bounding box
            x1, y1, x2, y2 = box.xyxy[0]
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values
            confidence = math.ceil((box.conf[0]*100))/100
            # class name
            cls = int(box.cls[0])
            class_name = classNames[cls]

            
            if confidence >= 0.65:

                #right zone detection
                if (x1 > 320 and x2 < 640) and (y1 > 250 and y2 > 250) and class_name != "Sidewalk":
                    # put box in cam
                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)
                    words = "In right zone , Move left"
                    # Say something
                    speak_async(words)
                    # object details
                    org = [x1, y1]
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    fontScale = 1
                    color = (255, 0, 0)
                    thickness = 2
                    cv2.putText(img, class_name, org, font, fontScale, color, thickness)
        
                    

                #left zone detection
                elif (x1 > 100 and x2 < 320) and (y1 > 250 and y2 > 250) and class_name != "Sidewalk":
                    # put box in camq
                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)
                    words = "In left zone , Move right"
                    # Say something
                    speak_async(words)
                    # object details
                    org = [x1, y1]
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    fontScale = 1
                    color = (255, 0, 0)
                    thickness = 2
                    cv2.putText(img, class_name, org, font, fontScale, color, thickness)
                    
                '''
                #Bigger than zone detection
                elif (x1 >= 1 and x2 <= 640) and (y1 < 250) and class_name != "Sidewalk":
                    # put box in cam
                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)
                    words = "covering camera , Back up"
                    # Say something
                    speak_async(words)
                    # object details
                    org = [x1, y1]
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    fontScale = 1
                    color = (255, 0, 0)
                    thickness = 2
                    cv2.putText(img, class_name, org, font, fontScale, color, thickness)
                '''
               

                
                    


    cv2.imshow('Webcam', img)
    if cv2.waitKey(1) == ord('q'):
        break



cap.release()
cv2.destroyAllWindows()