from ultralytics import YOLO
import cv2
import math 
import pyttsx3
import threading
import queue

# start webcam
cap = cv2.VideoCapture(0)
cap.set(3, 640)
cap.set(4, 480)

# Initialize the TTS engine
engine = pyttsx3.init()

# model
model = YOLO("yolo-Weights/session2/best.pt")

# object classes
classNames = ["Automobile", "Obstacle", "Person", "Road", "Sidewalk"]

# Define a function to handle TTS
# Function to handle TTS
def speak_async(text):
    def run_tts():
        try:
            engine.say(text)
            engine.runAndWait()
        except RuntimeError as e:
            # Suppress "run loop already started" error
            if "run loop already started" in str(e):
                pass
            else:
                raise

    # Run TTS in a background thread
    # for optimization
    tts_thread = threading.Thread(target=run_tts)
    tts_thread.start()

while True:
    
    success, img = cap.read()
    results = model(img, stream=True, verbose=False)
    #left zone - for visual only
    cv2.rectangle(img, (0,250), (320,480) , (255, 0 , 0),3, 1)
    #right zone - for visual only
    cv2.rectangle(img, (320, 250), (640,480), (255, 0 , 0),3, 1)
    
    # coordinates
    for r in results:
        boxes = r.boxes
        for box in boxes:
            # bounding box
            x1, y1, x2, y2 = box.xyxy[0]
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values
            confidence = math.ceil((box.conf[0]*100))/100
            # class name
            cls = int(box.cls[0])
            class_name = classNames[cls]

            #detection threshold
            if confidence >= 0.65:

                #right zone detection
                if (x1 > 320 and x2 < 640) and (y1 > 250 and y2 > 250) and class_name != "Sidewalk":
                    # put box in cam
                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)
                    words = class_name + " on right , Move left"
                    # Say something
                    speak_async(words)
                    # object details
                    org = [x1, y1]
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    fontScale = 1
                    color = (255, 0, 0)
                    thickness = 2
                    cv2.putText(img, class_name, org, font, fontScale, color, thickness)
        
                #left zone detection
                elif (x1 > 100 and x2 < 320) and (y1 > 250 and y2 > 250) and class_name != "Sidewalk":
                    # put box in camq
                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)
                    words = class_name + " on left , Move right"
                    # Say something
                    speak_async(words)
                    # object details
                    org = [x1, y1]
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    fontScale = 1
                    color = (255, 0, 0)
                    thickness = 2
                    cv2.putText(img, class_name, org, font, fontScale, color, thickness)
            
    #display cam
    cv2.imshow('Webcam', img)
    #kill button is q
    if cv2.waitKey(1) == ord('q'):
        break



cap.release()
cv2.destroyAllWindows()